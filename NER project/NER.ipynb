{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import nltk as nlp\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc(\"font\",size = 15)\n",
    "sns.set(style=\"dark\")\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.set(rc={'figure.figsize':(10,10)})\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns',500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data \n",
    "train = pd.read_csv(\"train.txt\", sep= '\\s+', engine='python')\n",
    "test = pd.read_csv(\"test.txt\",  sep = 'delimiter', header=None,engine='python')\n",
    "test.columns = ['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions and Observations: \n",
    "<br>\n",
    "1) Dealing with blank lines; the empty text with no tags in the set was not imported. \n",
    "\n",
    "2) The training set had close to 60,000 observations after removing blank lines, while the test set had close to 24,000 observations after blank line removal \n",
    "\n",
    "4) Missing values: The training set had 5 missing text values, and no missing tags, while the test set had one missing text value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#quick analysis \n",
    "def quick_analysis(df): \n",
    "    print('Data Types: \\n',df.dtypes)\n",
    "    print('\\nData Shape: \\n',df.shape)\n",
    "    print('\\nOverall Info: \\n', df.info())\n",
    "    print('\\nNull Values: \\n', df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Information  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types: \n",
      " text    object\n",
      "tag     object\n",
      "dtype: object\n",
      "\n",
      "Data Shape: \n",
      " (62730, 2)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62730 entries, 0 to 62729\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    62725 non-null  object\n",
      " 1   tag     62730 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 980.3+ KB\n",
      "\n",
      "Overall Info: \n",
      " None\n",
      "\n",
      "Null Values: \n",
      " text    5\n",
      "tag     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# training set \n",
    "quick_analysis(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Types: \n",
      " text    object\n",
      "dtype: object\n",
      "\n",
      "Data Shape: \n",
      " (23394, 1)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23394 entries, 0 to 23393\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    23393 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 182.9+ KB\n",
      "\n",
      "Overall Info: \n",
      " None\n",
      "\n",
      "Null Values: \n",
      " text    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#test set \n",
    "quick_analysis(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing: \n",
    "<br>\n",
    "1) Since the test set only contained one missing record we dropped it \n",
    "\n",
    "2) The missing records in the training set were from the text feature and we had five such records, these missing text records were also dropped due to their quantity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#dropping missing records \n",
    "test.dropna(inplace = True)\n",
    "train.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We Have 14876 unique words and 13 unique tags.\n"
     ]
    }
   ],
   "source": [
    "#number of unique tokens \n",
    "print(\"We Have {} unique words and {} unique tags.\".format(train.text.nunique(),train.tag.nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA \n",
    "<br>\n",
    "1) We took a look at the number of observations of each of our tags. By far the most common tag is O (outside), following that was the B tag (beginning of the chunk) \n",
    "\n",
    "2) The most common token was found to be the person entity either occurring at the beginning or inside the chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O                  59565\n",
       "B-person             660\n",
       "B-location           548\n",
       "I-person             335\n",
       "B-group              264\n",
       "I-location           245\n",
       "B-corporation        221\n",
       "I-creative-work      206\n",
       "I-product            203\n",
       "I-group              150\n",
       "B-product            142\n",
       "B-creative-work      140\n",
       "I-corporation         46\n",
       "Name: tag, dtype: int64"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tag counts \n",
    "train.tag.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#visualizing tag counts \n",
    "plt.figure(figsize = (15,6))\n",
    "sns.countplot(data= train[train.tag != 'O'], x= 'tag')\n",
    "plt.title(\"Tag Counts\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering: \n",
    "<br>\n",
    "\n",
    "1) We removed some of the noise in our text as a preprocessing step. We didn't remove stop words because they would get the 'O' tag either way, we removed urls so that our classifier doesn't mistakingly classify without looking at the website, and finally we removed parentheses and square brackets. \n",
    "\n",
    "2) We used DictVectorizer from sklearn to transform the text features into feature indices. This is done so that we can pass our input to the chosen algorithms \n",
    "\n",
    "3) Our transformed training vector has about 15000 feature indices \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noise Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def noise_removal(text): \n",
    "    #remove urls \n",
    "    text = re.sub('http://','',text)\n",
    "    #remove paranthesis \n",
    "    text = text.replace(')','').replace('(',\"\")\n",
    "    #remove square brackets \n",
    "    text = text.replace(']','').replace('[','')\n",
    "    return text \n",
    "\n",
    "train['text'] = train.text.apply(lambda x: noise_removal(x))\n",
    "test['text'] = test.text.apply(lambda x: noise_removal(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#preparing the train\n",
    "x = train.drop(\"tag\",axis = 1)\n",
    "v_train = DictVectorizer(sparse = False) \n",
    "x = v_train.fit_transform(x.to_dict('records'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The transformed training vector has 14832 feature indices.'"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#after transformation\n",
    "\"The transformed training vector has {} feature indices.\"\\\n",
    ".format(x.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary, Results, and Question Solutions: \n",
    "\n",
    "### Modeling Strategy:\n",
    "<br>\n",
    "We used a multitude of classic multi-label classifiers to predict text tags, the models included linear classifiers in SGD and linear support vector machines under the assumption that a linear hyperplane with max margins could be found, Naive Bayes classifier due to its capability of generating likelihoods of a text belonging to a tag, and RandomForest due to its ensemble nature which aggregates the results of decorrelated models. \n",
    "\n",
    "<br>\n",
    "\n",
    "### Prediction Results:\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "Each model was first evaluated based on a classification report where micro and macro averaging methods were used. The F1-score was the metric of choice as it allows us to gain a balance between precision and recall, our best F1-score came from the Perceptron and LinearSVC each with a micro-average of 0.33 and a macro-average of 0.26 with Naive Bayes being a close second.\n",
    "\n",
    "<br>\n",
    "\n",
    "Each model's performance and discriminative ability were found through subset accuracy and the Hamming loss. All models performed similarly with an accuracy near 95% and a loss close to 0.04. Our best performing model was Multinomial Naive Bayes with an accuracy of 95.8% and a loss of 0.042. LinearSVC was a close second which was expected due to its known prowess in text classification. \n",
    "\n",
    "<br>\n",
    "\n",
    "### Metric Choices: \n",
    "\n",
    "<br>\n",
    "\n",
    "Subset accuracy and the Hamming loss were chosen as metrics for the following reasons:\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "Since our problem is a multi-label classification problem, we must take into account that a prediction which contains a subset of the actual classes is better than one which contains none of them. \n",
    "\n",
    "<br>\n",
    "\n",
    "The Exact Match Ratio gives us the percentage of matches that have all their labels correctly classified, this has the disadvantage of ignoring partially correct answers, but will be useful as a strict metric of our model's ability to correctly classify all the labels.  \n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "To obtain a more accurate view of the performance of our classifier on a label-by-label basis we will also use the Hamming loss which is the fraction of labels that are incorrectly predicted (ie; fraction of wrong labels over total number of labels). \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing models and splitting the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, hamming_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data \n",
    "y = train.tag.values\n",
    "classes = np.unique(y)\n",
    "classes = classes.tolist()\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.3, random_state = 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusting Classes: \n",
    " \n",
    "Since our most common class is O (outside), it will make our predictions better than they actually are and to adjust for that, I will remove it from our classes as we evaluate our models\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-corporation',\n",
       " 'B-creative-work',\n",
       " 'B-group',\n",
       " 'B-location',\n",
       " 'B-person',\n",
       " 'B-product',\n",
       " 'I-corporation',\n",
       " 'I-creative-work',\n",
       " 'I-group',\n",
       " 'I-location',\n",
       " 'I-person',\n",
       " 'I-product']"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_class = classes.copy()\n",
    "new_class.pop()\n",
    "new_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Our Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
       "                            early_stopping=False, fit_intercept=True,\n",
       "                            loss='hinge', max_iter=1000, n_iter_no_change=5,\n",
       "                            n_jobs=None, random_state=None, shuffle=True,\n",
       "                            tol=0.001, validation_fraction=0.1, verbose=0,\n",
       "                            warm_start=False)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Perceptron \n",
    "per = Perceptron(n_jobs= -1)\n",
    "per.fit(x_train,y_train)\n",
    "\n",
    "# SGD Linear Classifier \n",
    "sgd = SGDClassifier(n_jobs= -1 )\n",
    "sgd.fit(x_train,y_train)\n",
    "\n",
    "#SVC classifier \n",
    "svc = LinearSVC(random_state= 0)\n",
    "svc.fit(x_train,y_train)\n",
    "\n",
    "#Naive Bayes classifier for multinomial models\n",
    "nb = MultinomialNB(alpha= 0.01)\n",
    "nb.fit(x_train,y_train)\n",
    "\n",
    "# RandomForest\n",
    "rf = RandomForestClassifier(n_jobs =-1, n_estimators= 2,max_depth=6, random_state= 0) \n",
    "rf.fit(x_train,y_train)\n",
    "\n",
    "#Passive Aggressive Classifier\n",
    "pas = PassiveAggressiveClassifier()\n",
    "pas.fit(x_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions and Model Evaluation \n",
    "\n",
    "Here we predict on the data we held out for validation and use a classification report to check our model's predictive power \n",
    "\n",
    "For evaluating our model we will use the hamming loss and the exact match ratio (subset accuracy) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# predictions\n",
    "per_pred = per.predict(x_test)\n",
    "sgd_pred= sgd.predict(x_test)\n",
    "nb_pred = nb.predict(x_test)\n",
    "svc_pred = svc.predict(x_test)\n",
    "rf_pred = rf.predict(x_test)\n",
    "pas_pred = pas.predict(x_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed Model Results: \n",
      "\n",
      "Perceptron classification report: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation       0.42      0.48      0.44        67\n",
      "B-creative-work       0.11      0.03      0.04        40\n",
      "        B-group       0.53      0.17      0.26        98\n",
      "     B-location       0.80      0.29      0.43       174\n",
      "       B-person       0.76      0.32      0.45       201\n",
      "      B-product       1.00      0.24      0.39        37\n",
      "  I-corporation       0.25      0.10      0.14        10\n",
      "I-creative-work       0.32      0.16      0.21        56\n",
      "        I-group       0.17      0.05      0.07        43\n",
      "     I-location       0.29      0.12      0.17        76\n",
      "       I-person       0.59      0.18      0.28        87\n",
      "      I-product       0.41      0.14      0.21        50\n",
      "\n",
      "      micro avg       0.55      0.23      0.33       939\n",
      "      macro avg       0.47      0.19      0.26       939\n",
      "   weighted avg       0.57      0.23      0.32       939\n",
      "\n",
      "\n",
      "\n",
      "Perceptron Subset Accuracy: 95.637%\n",
      "\n",
      "Perceptron Hamming Loss: 4.363%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SGD classification report: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation       1.00      0.24      0.39        67\n",
      "B-creative-work       1.00      0.00      0.00        40\n",
      "        B-group       1.00      0.00      0.00        98\n",
      "     B-location       1.00      0.02      0.03       174\n",
      "       B-person       1.00      0.09      0.16       201\n",
      "      B-product       1.00      0.05      0.10        37\n",
      "  I-corporation       1.00      0.00      0.00        10\n",
      "I-creative-work       1.00      0.00      0.00        56\n",
      "        I-group       1.00      0.00      0.00        43\n",
      "     I-location       1.00      0.00      0.00        76\n",
      "       I-person       0.86      0.07      0.13        87\n",
      "      I-product       1.00      0.00      0.00        50\n",
      "\n",
      "      micro avg       0.98      0.05      0.09       939\n",
      "      macro avg       0.99      0.04      0.07       939\n",
      "   weighted avg       0.99      0.05      0.08       939\n",
      "\n",
      "\n",
      "\n",
      "SGD Subset Accuracy: 95.249%\n",
      "\n",
      "SGD Hamming Loss: 4.751%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NB classification report: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation       0.86      0.46      0.60        67\n",
      "B-creative-work       0.14      0.03      0.04        40\n",
      "        B-group       0.61      0.17      0.27        98\n",
      "     B-location       0.80      0.30      0.44       174\n",
      "       B-person       0.81      0.26      0.39       201\n",
      "      B-product       1.00      0.22      0.36        37\n",
      "  I-corporation       0.33      0.10      0.15        10\n",
      "I-creative-work       0.28      0.09      0.14        56\n",
      "        I-group       0.29      0.05      0.08        43\n",
      "     I-location       0.30      0.09      0.14        76\n",
      "       I-person       0.59      0.20      0.29        87\n",
      "      I-product       0.38      0.12      0.18        50\n",
      "\n",
      "      micro avg       0.65      0.21      0.32       939\n",
      "      macro avg       0.53      0.17      0.26       939\n",
      "   weighted avg       0.62      0.21      0.31       939\n",
      "\n",
      "\n",
      "\n",
      "NB Subset Accuracy: 95.818%\n",
      "\n",
      "NB Hamming Loss: 4.182%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "LinearSVC classification report: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation       0.86      0.46      0.60        67\n",
      "B-creative-work       0.07      0.03      0.04        40\n",
      "        B-group       0.61      0.17      0.27        98\n",
      "     B-location       0.80      0.30      0.44       174\n",
      "       B-person       0.80      0.28      0.42       201\n",
      "      B-product       1.00      0.24      0.39        37\n",
      "  I-corporation       0.33      0.10      0.15        10\n",
      "I-creative-work       0.26      0.11      0.15        56\n",
      "        I-group       0.29      0.05      0.08        43\n",
      "     I-location       0.30      0.09      0.14        76\n",
      "       I-person       0.59      0.20      0.29        87\n",
      "      I-product       0.38      0.12      0.18        50\n",
      "\n",
      "      micro avg       0.64      0.22      0.33       939\n",
      "      macro avg       0.52      0.18      0.26       939\n",
      "   weighted avg       0.62      0.22      0.32       939\n",
      "\n",
      "\n",
      "\n",
      "LinearSVC Subset Accuracy: 95.791%\n",
      "\n",
      "LinearSVC Hamming Loss: 4.209%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "RandomForest Classifier classification report: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation       1.00      0.00      0.00        67\n",
      "B-creative-work       1.00      0.00      0.00        40\n",
      "        B-group       1.00      0.00      0.00        98\n",
      "     B-location       1.00      0.00      0.00       174\n",
      "       B-person       1.00      0.00      0.00       201\n",
      "      B-product       1.00      0.00      0.00        37\n",
      "  I-corporation       1.00      0.00      0.00        10\n",
      "I-creative-work       1.00      0.00      0.00        56\n",
      "        I-group       1.00      0.00      0.00        43\n",
      "     I-location       1.00      0.00      0.00        76\n",
      "       I-person       1.00      0.00      0.00        87\n",
      "      I-product       1.00      0.00      0.00        50\n",
      "\n",
      "      micro avg       1.00      0.00      0.00       939\n",
      "      macro avg       1.00      0.00      0.00       939\n",
      "   weighted avg       1.00      0.00      0.00       939\n",
      "\n",
      "\n",
      "\n",
      "RandomForest Classifier Subset Accuracy: 95.010%\n",
      "\n",
      "RandomForest Classifier Hamming Loss: 4.990%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Passive Aggressive Classifier classification report: \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "  B-corporation       0.86      0.48      0.62        67\n",
      "B-creative-work       0.14      0.07      0.10        40\n",
      "        B-group       0.26      0.19      0.22        98\n",
      "     B-location       0.74      0.28      0.41       174\n",
      "       B-person       0.75      0.32      0.45       201\n",
      "      B-product       1.00      0.27      0.43        37\n",
      "  I-corporation       0.09      0.10      0.10        10\n",
      "I-creative-work       0.15      0.20      0.17        56\n",
      "        I-group       0.20      0.09      0.13        43\n",
      "     I-location       0.24      0.05      0.09        76\n",
      "       I-person       0.61      0.20      0.30        87\n",
      "      I-product       0.46      0.12      0.19        50\n",
      "\n",
      "      micro avg       0.49      0.23      0.32       939\n",
      "      macro avg       0.46      0.20      0.27       939\n",
      "   weighted avg       0.55      0.23      0.32       939\n",
      "\n",
      "\n",
      "\n",
      "Passive Aggressive Classifier Subset Accuracy: 95.377%\n",
      "\n",
      "Passive Aggressive Classifier Hamming Loss: 4.623%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Reports \n",
    "\n",
    "models = ['Perceptron','SGD', 'NB', 'LinearSVC','RandomForest Classifier','Passive Aggressive Classifier']\n",
    "preds = [per_pred, sgd_pred, nb_pred, svc_pred, rf_pred, pas_pred]\n",
    "\n",
    "def class_report(models, preds): \n",
    "\n",
    " \n",
    "\n",
    "    print('Detailed Model Results: \\n')\n",
    "    for pred,model in zip(preds,models):\n",
    "\n",
    "        print(f\"{model} classification report: \\n{classification_report(y_test,pred,zero_division=1,labels=new_class)}\")\n",
    "        print('\\n')\n",
    "        print(f\"{model} Subset Accuracy: {accuracy_score(y_test,pred):.3%}\\n\")\n",
    "        print(f\"{model} Hamming Loss: {hamming_loss(y_test,pred, ):.3%}\\n\")\n",
    "        print('\\n')\n",
    "        print('\\n')\n",
    "\n",
    "class_report(models,preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Set Predictions \n",
    "\n",
    "We use our two best models; NB, and linearSVC for our test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#transform\n",
    "test_arr = v_train.transform(test.to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_test_pred = nb.predict(test_arr)\n",
    "svc_test_pred = svc.predict(test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appending predictions \n",
    "test['NB_predicitons'] = nb_test_pred\n",
    "test['LinearSVC_predictions']= svc_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>NB_predicitons</th>\n",
       "      <th>LinearSVC_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&amp;</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gt</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>;</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>*</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23389</th>\n",
       "      <td>with</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23390</th>\n",
       "      <td>this</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23391</th>\n",
       "      <td>dress</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23392</th>\n",
       "      <td>code</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23393</th>\n",
       "      <td>😂</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23393 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        text NB_predicitons LinearSVC_predictions\n",
       "0          &              O                     O\n",
       "1         gt              O                     O\n",
       "2          ;              O                     O\n",
       "3          *              O                     O\n",
       "4        The              O                     O\n",
       "...      ...            ...                   ...\n",
       "23389   with              O                     O\n",
       "23390   this              O                     O\n",
       "23391  dress              O                     O\n",
       "23392   code              O                     O\n",
       "23393      😂              O                     O\n",
       "\n",
       "[23393 rows x 3 columns]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output to csv \n",
    "test.to_csv(\"test_predictions.csv\",index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Further Work: \n",
    "\n",
    "To improve our results, particularly our precision and recall (and hence our F-score), I would proceed as follows \n",
    "\n",
    "<br>\n",
    "\n",
    "1) Get the full sentences which our tokens come from, this will allow us to identify the context the tokens are being used in, and would allow for better POS-tagging and feature engineering \n",
    "\n",
    "\n",
    "\n",
    "2) Utilize Bidirectional LSTM and recurrent neural networks to further improve our predictive power "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "230.4px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.4,
   "position": {
    "height": "144px",
    "left": "398px",
    "right": "20px",
    "top": "162px",
    "width": "499.4px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
